{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T21:57:40.307674Z","iopub.execute_input":"2025-11-10T21:57:40.307986Z","iopub.status.idle":"2025-11-10T21:57:40.313551Z","shell.execute_reply.started":"2025-11-10T21:57:40.307935Z","shell.execute_reply":"2025-11-10T21:57:40.312426Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\n**Welcome to the Kaggle 5-day Agents course!**\n\nIn the previous notebook, you built a **single agent** that could take action. Now, you'll learn how to scale up by building **agent teams**.\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n\n## ‚ÄºÔ∏è Please Read\n\n> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n\n> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n\n**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Section 1: Setup\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:36:46.598378Z","iopub.execute_input":"2025-11-11T11:36:46.598734Z","iopub.status.idle":"2025-11-11T11:36:46.709793Z","shell.execute_reply.started":"2025-11-11T11:36:46.598704Z","shell.execute_reply":"2025-11-11T11:36:46.708465Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### 1.3: Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:36:52.257172Z","iopub.execute_input":"2025-11-11T11:36:52.257466Z","iopub.status.idle":"2025-11-11T11:37:35.471047Z","shell.execute_reply.started":"2025-11-11T11:36:52.257449Z","shell.execute_reply":"2025-11-11T11:37:35.469405Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 1.4: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"cell_type":"code","source":"retry_config=types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:38:57.136114Z","iopub.execute_input":"2025-11-11T11:38:57.137679Z","iopub.status.idle":"2025-11-11T11:38:57.143897Z","shell.execute_reply.started":"2025-11-11T11:38:57.137649Z","shell.execute_reply":"2025-11-11T11:38:57.142388Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"---\n## ü§î Section 2: Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:39:05.837418Z","iopub.execute_input":"2025-11-11T11:39:05.837666Z","iopub.status.idle":"2025-11-11T11:39:05.844631Z","shell.execute_reply.started":"2025-11-11T11:39:05.837650Z","shell.execute_reply":"2025-11-11T11:39:05.843268Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:39:10.256991Z","iopub.execute_input":"2025-11-11T11:39:10.257277Z","iopub.status.idle":"2025-11-11T11:39:10.262580Z","shell.execute_reply.started":"2025-11-11T11:39:10.257259Z","shell.execute_reply":"2025-11-11T11:39:10.261807Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a root agent, or coordinator:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:39:15.090914Z","iopub.execute_input":"2025-11-11T11:39:15.091807Z","iopub.status.idle":"2025-11-11T11:39:15.096972Z","shell.execute_reply.started":"2025-11-11T11:39:15.091785Z","shell.execute_reply":"2025-11-11T11:39:15.096105Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"Here we're using `AgentTool` to wrap the sub-agents to make them callable tools for the root agent. We'll explore `AgentTool` in-detail on Day 2.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"What are the latest advancements in quantum computing and what do they mean for AI?\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:39:19.340553Z","iopub.execute_input":"2025-11-11T11:39:19.340811Z","iopub.status.idle":"2025-11-11T11:39:28.596003Z","shell.execute_reply.started":"2025-11-11T11:39:19.340794Z","shell.execute_reply":"2025-11-11T11:39:28.595247Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What are the latest advancements in quantum computing and what do they mean for AI?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchCoordinator > Quantum computing is rapidly advancing, with significant breakthroughs in both hardware and algorithms. These advancements hold profound implications for Artificial Intelligence.\n\n**Key Advancements:**\n\n*   **Hardware Innovations:** Progress includes developing scalable network technologies, improving integrated photonics for trapped-ion devices, utilizing new materials, and building processors with over 1,000 qubits. There's also a focus on extending qubit coherence times and enhancing device fidelity.\n*   **Algorithmic and Error Correction Advances:** Crucial developments in quantum error correction (QEC) and frameworks like Algorithmic Fault Tolerance (AFT) are increasing the reliability of quantum computers. The creation of logical qubits that outperform physical ones marks a significant step towards more robust quantum systems.\n\n**Implications for AI:**\n\n*   **Enhanced AI Capabilities:** Quantum computing has the potential to revolutionize AI by enabling much faster training of AI models, improving the optimization of complex algorithms, and allowing for the efficient processing of massive datasets. This could lead to AI tackling problems currently considered impossible.\n*   **Hybrid Quantum-Classical Approaches:** The trend is towards integrating AI with quantum systems through hybrid approaches, which are essential for optimizing quantum computations and developing practical AI applications.\n*   **Overcoming Classical Limitations:** Quantum computers can address complex challenges that are beyond the reach of even the most powerful classical computers, opening up new frontiers for AI research and development.\n\n**Remaining Challenges:**\n\nDespite the rapid progress, challenges persist, including the need for specialized expertise, further hardware development, sophisticated algorithms, and addressing concerns related to cybersecurity, privacy, and potential biases in AI systems.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## üö• Section 3: Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:39:40.067026Z","iopub.execute_input":"2025-11-11T11:39:40.067287Z","iopub.status.idle":"2025-11-11T11:39:40.073186Z","shell.execute_reply.started":"2025-11-11T11:39:40.067268Z","shell.execute_reply":"2025-11-11T11:39:40.071710Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\",  # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:39:45.361807Z","iopub.execute_input":"2025-11-11T11:39:45.362434Z","iopub.status.idle":"2025-11-11T11:39:45.367184Z","shell.execute_reply.started":"2025-11-11T11:39:45.362415Z","shell.execute_reply":"2025-11-11T11:39:45.366190Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\",  # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:39:49.959535Z","iopub.execute_input":"2025-11-11T11:39:49.960961Z","iopub.status.idle":"2025-11-11T11:39:49.966554Z","shell.execute_reply.started":"2025-11-11T11:39:49.960906Z","shell.execute_reply":"2025-11-11T11:39:49.965619Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:39:55.239338Z","iopub.execute_input":"2025-11-11T11:39:55.239672Z","iopub.status.idle":"2025-11-11T11:39:55.245500Z","shell.execute_reply.started":"2025-11-11T11:39:55.239655Z","shell.execute_reply":"2025-11-11T11:39:55.244553Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a blog post about the benefits of multi-agent systems for software developers\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:39:59.393255Z","iopub.execute_input":"2025-11-11T11:39:59.393580Z","iopub.status.idle":"2025-11-11T11:40:05.128685Z","shell.execute_reply.started":"2025-11-11T11:39:59.393559Z","shell.execute_reply":"2025-11-11T11:40:05.127519Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about the benefits of multi-agent systems for software developers\nOutlineAgent > Okay, I am OutlineAgent. Here is a blog post outline about the benefits of multi-agent systems for software developers.\n\n---\n\n### Blog Post Outline:\n\n**Headline:** Beyond Single Threads: How Multi-Agent Systems Are Revolutionizing Software Development\n\n**Introduction Hook:** Tired of wrestling with monolithic codebases and the limitations of single-threaded execution? Imagine a world where your software components can collaborate, adapt, and solve complex problems more efficiently. This is the promise of Multi-Agent Systems (MAS), and for software developers, it's a paradigm shift that unlocks incredible potential.\n\n**Main Sections:**\n\n1.  **Enhanced Problem Solving and Robustness**\n    *   **Decomposition and Specialization:** Break down complex tasks into smaller, manageable agents, each with a specific purpose and expertise. This leads to more modular, understandable, and maintainable code.\n    *   **Resilience through Redundancy and Diversity:** If one agent fails, others can often compensate or take over its tasks, leading to more robust and fault-tolerant systems compared to single-point-of-failure architectures.\n    *   **Adaptive Behavior:** Agents can sense their environment and react intelligently, allowing systems to adapt to changing conditions and unforeseen circumstances without explicit reprogramming for every scenario.\n\n2.  **Improved Efficiency and Performance**\n    *   **Parallelism and Concurrency:** Agents can operate and execute tasks concurrently, significantly speeding up processing times for complex computations and simulations, especially on multi-core processors.\n    *   **Distributed Intelligence:** Distribute agents across different machines or platforms to leverage computational resources effectively and handle geographically dispersed data or operations.\n    *   **Optimized Resource Utilization:** Agents can be designed to manage and allocate resources dynamically, ensuring that system resources are used efficiently and bottlenecks are minimized.\n\n3.  **Facilitating Complex Interactions and emergent Behavior**\n    *   **Collaborative Problem Solving:** Agents can communicate and coordinate their efforts to achieve common goals that would be difficult or impossible for a single entity to accomplish alone.\n    *   **Emergent Intelligence:** Through the interactions and learning of individual agents, complex, intelligent behaviors can emerge at the system level, leading to novel solutions and insights.\n    *   **Modeling Real-World Scenarios:** MAS provides a natural fit for modeling systems with interacting entities, such as supply chains, traffic simulations, or even social networks, offering developers a powerful tool for realistic simulation and analysis.\n\n**Concluding Thought:** Embracing multi-agent systems isn't just about adopting a new technology; it's about fundamentally rethinking how we design and build intelligent, resilient, and efficient software. For developers ready to move beyond traditional architectures, MAS offers a powerful pathway to tackling increasingly complex challenges and creating the next generation of sophisticated applications.\n\n---\nWriterAgent > ### Beyond Single Threads: How Multi-Agent Systems Are Revolutionizing Software Development\n\nTired of wrestling with monolithic codebases and the limitations of single-threaded execution? Imagine a world where your software components can collaborate, adapt, and solve complex problems more efficiently. This is the promise of Multi-Agent Systems (MAS), and for software developers, it's a paradigm shift that unlocks incredible potential.\n\nOne of the primary benefits of MAS lies in **enhanced problem-solving and robustness**. By breaking down complex tasks into smaller, specialized agents, you create more modular, maintainable, and understandable code. This decomposition also fosters resilience; if one agent falters, others can often compensate, leading to more fault-tolerant systems than traditional architectures. Furthermore, agents can sense their environment and react intelligently, enabling systems to adapt to unforeseen circumstances without constant reprogramming.\n\nMAS also dramatically **improves efficiency and performance**. Agents can operate concurrently, leveraging parallelism to speed up computations, especially on multi-core processors. This distributed intelligence allows tasks to be spread across various machines, optimizing resource utilization and handling geographically dispersed operations.\n\nFinally, MAS excels at **facilitating complex interactions and emergent behavior**. Agents can communicate and coordinate to achieve goals unattainable by a single entity. This interaction can lead to emergent intelligence, where complex, novel solutions arise from the collective behavior of simpler agents. It also provides a natural way to model real-world scenarios involving numerous interacting entities, offering powerful tools for simulation and analysis.\n\nEmbracing multi-agent systems is about rethinking software design for intelligence, resilience, and efficiency, paving the way for the next generation of sophisticated applications.\nEditorAgent > ### Beyond Single Threads: How Multi-Agent Systems Are Revolutionizing Software Development\n\nAre you tired of wrestling with monolithic codebases and the inherent limitations of single-threaded execution? Imagine a software environment where components collaborate seamlessly, adapt intelligently, and tackle complex problems with unprecedented efficiency. This is the compelling future offered by Multi-Agent Systems (MAS), a paradigm shift poised to unlock extraordinary potential for software developers.\n\nOne of the most significant advantages of MAS lies in **enhanced problem-solving and system robustness**. By decomposing intricate tasks into smaller, specialized agents, developers can craft more modular, maintainable, and inherently understandable code. This modularity also cultivates resilience; should one agent encounter an issue, others can often step in to compensate, leading to systems far more fault-tolerant than traditional architectures. Furthermore, agents are designed to perceive their environment and react intelligently, enabling systems to adapt to unforeseen circumstances dynamically, without requiring constant manual reprogramming.\n\nMAS also offers a dramatic leap in **improving efficiency and performance**. Agents can operate concurrently, harnessing the power of parallelism to accelerate computations, particularly on modern multi-core processors. This distributed intelligence allows tasks to be spread across multiple machines, optimizing resource utilization and effectively managing geographically dispersed operations.\n\nFinally, MAS excels at **facilitating intricate interactions and fostering emergent behavior**. Agents can communicate and coordinate their actions to achieve collective goals that would be unattainable for a single entity. This dynamic interaction can give rise to emergent intelligence, where sophisticated and novel solutions arise organically from the collective actions of simpler agents. This approach also provides a natural and powerful framework for modeling real-world scenarios involving numerous interacting entities, offering developers robust tools for simulation and in-depth analysis.\n\nEmbracing multi-agent systems signifies more than just adopting a new technology; it represents a fundamental rethinking of software design to prioritize intelligence, resilience, and efficiency. For developers ready to move beyond conventional architectures, MAS offers a clear and powerful pathway to tackling increasingly complex challenges and building the next generation of sophisticated applications.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n## üõ£Ô∏è Section 4: Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:40:21.244950Z","iopub.execute_input":"2025-11-11T11:40:21.245270Z","iopub.status.idle":"2025-11-11T11:40:21.250280Z","shell.execute_reply.started":"2025-11-11T11:40:21.245252Z","shell.execute_reply":"2025-11-11T11:40:21.249623Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:40:25.140489Z","iopub.execute_input":"2025-11-11T11:40:25.140874Z","iopub.status.idle":"2025-11-11T11:40:25.147722Z","shell.execute_reply.started":"2025-11-11T11:40:25.140844Z","shell.execute_reply":"2025-11-11T11:40:25.146776Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:40:29.603103Z","iopub.execute_input":"2025-11-11T11:40:29.603387Z","iopub.status.idle":"2025-11-11T11:40:29.608947Z","shell.execute_reply.started":"2025-11-11T11:40:29.603371Z","shell.execute_reply":"2025-11-11T11:40:29.608225Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:40:33.852963Z","iopub.execute_input":"2025-11-11T11:40:33.853223Z","iopub.status.idle":"2025-11-11T11:40:33.859273Z","shell.execute_reply.started":"2025-11-11T11:40:33.853203Z","shell.execute_reply":"2025-11-11T11:40:33.857855Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"üëâ **Then we bring the agents together under a parallel agent, which is itself nested inside of a sequential agent.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:40:40.370131Z","iopub.execute_input":"2025-11-11T11:40:40.370445Z","iopub.status.idle":"2025-11-11T11:40:40.376519Z","shell.execute_reply.started":"2025-11-11T11:40:40.370423Z","shell.execute_reply":"2025-11-11T11:40:40.375396Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Run the daily executive briefing on Tech, Health, and Finance\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:40:48.017985Z","iopub.execute_input":"2025-11-11T11:40:48.018210Z","iopub.status.idle":"2025-11-11T11:40:54.470122Z","shell.execute_reply.started":"2025-11-11T11:40:48.018196Z","shell.execute_reply":"2025-11-11T11:40:54.469228Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nHealthResearcher > **Health Breakthroughs**\n\n*   **Gene Therapy for Inherited Diseases:** Advances in gene therapy, particularly using CRISPR-Cas9 technology, are revolutionizing the treatment of genetic disorders like sickle cell anemia and inherited hearing loss. This approach involves correcting or replacing faulty genes.\n    *   **Practical Application:** Restoring vision, enabling a deaf child to hear, and treating blood disorders are current and near-term applications.\n    *   **Timeline:** Clinical trials are ongoing, with some therapies already approved and expanding applications anticipated within 1-5 years.\n\n*   **CAR T-Cell Therapy for Brain Cancer:** This immunotherapy approach re-engineers a patient's own immune cells (T-cells) to target and destroy cancer cells. Initial success in blood cancers is now showing promise for brain tumors.\n    *   **Practical Application:** Offering new hope for pediatric and adult brain cancer patients, potentially improving treatment outcomes.\n    *   **Timeline:** Early-stage clinical trials are demonstrating benefits, with wider application expected in 5-10 years as research progresses.\n\n*   **AI-Enhanced Diagnostics:** Artificial intelligence is improving the accuracy and speed of medical diagnoses, from detecting heart conditions to enhancing mammograms and identifying new uses for existing drugs.\n    *   **Practical Application:** Faster and more accurate diagnoses for various diseases, leading to earlier intervention and personalized treatment plans.\n    *   **Timeline:** AI in diagnostics is already being implemented and is expected to become standard practice across many medical fields within the next 3-7 years.\nFinanceResearcher > **Tech Trends**\n\n1.  **AI Agentic Workflows & Context Engineering:** AI is shifting from basic chatbots to sophisticated agents capable of autonomous, multi-step tasks. This requires advanced \"context engineering\" to provide structured information for reliable performance.\n    *   **Market Implication:** Companies are investing heavily in AI infrastructure, particularly GPUs, to handle these demanding workloads. This drives demand for specialized orchestration tools like Kubernetes.\n    *   **Future Outlook:** Expect continued rapid development in AI agent capabilities, with significant implications for automation across industries. Infrastructure management will remain critical.\n\n2.  **5G Expansion & Quantum Computing:** 5G technology continues its rollout, offering faster speeds and enabling new \"phygital\" experiences. Concurrently, quantum computing is advancing, with potential applications in finance (optimization, risk analysis) and manufacturing (supply chain efficiency).\n    *   **Market Implication:** These advancements are reshaping industries and driving significant global energy investments.\n    *   **Future Outlook:** The convergence of these technologies will unlock further innovation, though quantum computing's widespread practical application is still developing.\n\n**Health Trends**\n\n1.  **Personalized Healthcare & AI Diagnostics:** AI is being integrated to tailor wellness plans and communication strategies, addressing individual patient needs. AI is also increasingly used for early detection of diseases like cancer, strokes, and heart problems.\n    *   **Market Implication:** This drives demand for advanced diagnostics and personalized treatment solutions.\n    *   **Future Outlook:** Expect wider adoption of AI-driven decision support for medical professionals and a greater focus on preventative care.\n\n2.  **Genomics and Gene Editing:** Technologies like CRISPR are moving towards clinical applications for genetic conditions, with ongoing research into their use for cancer and cardiovascular diseases.\n    *   **Market Implication:** This opens new avenues for targeted treatments and therapies.\n    *   **Future Outlook:** Continued ethical discussions and regulatory developments will shape the clinical integration of these powerful biotechnologies.\n\n**Finance Trends**\n\n1.  **AI Integration & Data-Driven Decision Making:** AI is being embedded into financial systems to enhance decision-making, forecasting, and operational efficiency.\n    *   **Market Implication:** This leads to a demand for finance professionals with strong analytical and digital transformation skills. Mega-mergers are also on the rise, creating larger, more resilient financial institutions.\n    *   **Future Outlook:** Financial services will become increasingly data-centric, with AI playing a pivotal role in strategy and execution.\n\n2.  **Market Volatility & Investor Caution:** Global equity markets face potential corrections due to persistent inflation and higher interest rates.\n    *   **Market Implication:** Investors are adopting a more vigilant stance, with conservative outlooks for the global economy.\n    *   **Future Outlook:** Navigating market volatility will require robust risk management and strategic adaptability from financial institutions and investors.\nTechResearcher > **Key AI/ML Trends in 2025**\n\nThree significant AI/ML trends emerging in 2025 are:\n\n1.  **Generative AI Expansion:** Beyond content creation, Generative AI is now being used for complex tasks like drug discovery, material science, and even creating new proteins. Major companies like **Google** (with models like Muse and Imagen) and **OpenAI** (GPT models) are at the forefront of this advancement. The potential impact includes accelerated scientific research, personalized medicine, and novel material development.\n\n2.  **Agentic AI and Autonomous Systems:** AI systems capable of independent action and decision-making are gaining prominence. These \"agents\" can manage schedules, resolve conflicts, and even collaborate to complete complex tasks with minimal human intervention. Companies like **Microsoft** (with Copilot and developing AI agents) are actively involved. The impact is a revolution in work processes, increased automation, and more efficient problem-solving across various sectors.\n\n3.  **AI-Powered Digital Twins and Predictive Healthcare:** The creation of AI-driven virtual replicas of physical systems, particularly the human body, is set to revolutionize healthcare. These digital twins can forecast disease development, personalize treatments, and predict health risks. This trend promises a shift towards proactive and personalized healthcare. The impact could be a significant reduction in disease burden and more effective medical interventions.\n\n**Leading Companies:** Key players actively shaping these trends include **Google**, **Microsoft**, **OpenAI**, **NVIDIA** (driving hardware advancements), **Amazon Web Services (AWS)**, and **IBM**. These companies are developing foundational models, AI infrastructure, and specialized AI solutions.\n\n**Potential Impact:** The overarching impact of these trends is a more intelligent, automated, and personalized world. From accelerating scientific breakthroughs and revolutionizing healthcare to transforming how we work and interact with technology, AI/ML in 2025 promises unprecedented advancements. However, this also brings a heightened need for responsible AI development, focusing on ethics, security, and bias mitigation.\nAggregatorAgent > ## Executive Summary: AI, Health, and Finance Convergence\n\nArtificial intelligence is rapidly transforming both healthcare and finance, creating a landscape of increased personalization, automation, and efficiency. In health, AI is driving breakthroughs from **AI-enhanced diagnostics** and **personalized healthcare** to the revolutionary potential of **gene therapy** (CRISPR) and **CAR T-cell therapy** for genetic disorders and brain cancers. These advancements promise earlier intervention, tailored treatments, and the potential to cure previously intractable diseases within the next 1-10 years.\n\nSimultaneously, **AI agentic workflows** are reshaping industries, with sophisticated AI systems capable of autonomous, multi-step tasks. This necessitates robust AI infrastructure, driving significant investment in hardware like GPUs. In finance, this translates to enhanced **data-driven decision-making**, improved forecasting, and operational efficiency. However, this period of rapid technological advancement is juxtaposed with **market volatility**, urging caution and robust risk management. The convergence of these trends points towards a future where AI accelerates scientific discovery and personalized services, while demanding careful navigation of evolving technological capabilities and economic uncertainties.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n## ‚û∞ Section 5: Loop Workflows - The Refinement Cycle\n\n**The Problem: One-Shot Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\",  # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:41:06.337395Z","iopub.execute_input":"2025-11-11T11:41:06.337727Z","iopub.status.idle":"2025-11-11T11:41:06.343048Z","shell.execute_reply.started":"2025-11-11T11:41:06.337709Z","shell.execute_reply":"2025-11-11T11:41:06.342355Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\",  # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:41:11.098934Z","iopub.execute_input":"2025-11-11T11:41:11.099888Z","iopub.status.idle":"2025-11-11T11:41:11.105090Z","shell.execute_reply.started":"2025-11-11T11:41:11.099866Z","shell.execute_reply":"2025-11-11T11:41:11.103717Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:41:16.484776Z","iopub.execute_input":"2025-11-11T11:41:16.485192Z","iopub.status.idle":"2025-11-11T11:41:16.491631Z","shell.execute_reply.started":"2025-11-11T11:41:16.485155Z","shell.execute_reply":"2025-11-11T11:41:16.490283Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    output_key=\"current_story\",  # It overwrites the story with the new, refined version.\n    tools=[\n        FunctionTool(exit_loop)\n    ],  # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:41:24.946086Z","iopub.execute_input":"2025-11-11T11:41:24.946459Z","iopub.status.idle":"2025-11-11T11:41:24.953470Z","shell.execute_reply.started":"2025-11-11T11:41:24.946440Z","shell.execute_reply":"2025-11-11T11:41:24.952371Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2,  # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:41:29.578505Z","iopub.execute_input":"2025-11-11T11:41:29.578908Z","iopub.status.idle":"2025-11-11T11:41:29.585737Z","shell.execute_reply.started":"2025-11-11T11:41:29.578875Z","shell.execute_reply":"2025-11-11T11:41:29.584231Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loop and Sequential Agents created.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T11:41:33.897064Z","iopub.execute_input":"2025-11-11T11:41:33.897370Z","iopub.status.idle":"2025-11-11T11:41:40.878864Z","shell.execute_reply.started":"2025-11-11T11:41:33.897308Z","shell.execute_reply":"2025-11-11T11:41:40.877573Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\nInitialWriterAgent > Elias had tended the Solitude Point lighthouse for twenty years, his world confined to the rhythmic sweep of the beam and the ceaseless whisper of the sea. One blustery evening, while sorting through a dusty crate of salvaged flotsam, his fingers brushed against something impossibly smooth. He pulled out a rolled parchment, unlike any paper he‚Äôd ever seen. It pulsed with a faint, emerald light. Unfurling it revealed not ink, but luminous lines tracing an unknown archipelago. Strange symbols dotted the coastlines, symbols that seemed to hum with an ancient energy. The map, impossibly, seemed to shift and reconfigure as he watched, its glow intensifying. Elias, a man who thought he‚Äôd seen it all, felt a shiver that had nothing to do with the wind.\nCriticAgent > The story effectively establishes Elias's isolated existence and introduces a compelling mystery with the discovery of the glowing map. However, to deepen the impact and propel the narrative forward, consider the following:\n\n1.  **Deepen Elias's reaction:** While the shiver is a good start, Elias has been alone for twenty years. Explore his internal monologue more. Is it fear, excitement, disbelief, or a longing for something beyond his solitary life? Show, don't just tell, his profound reaction to this artifact that shatters his routine.\n2.  **Foreshadow the map's nature:** The description of the map is intriguing, but hinting at its potential purpose or origin, even subtly, would add more layers. Are the symbols vaguely familiar, or do they suggest a specific kind of power or civilization? This could create anticipation for what Elias might do next.\n3.  **Introduce a tangible connection or consequence:** The map is magical and shifts, but what is its immediate effect on Elias or his surroundings? Does the lighthouse beam falter? Does he hear a distant call? A small, immediate consequence would make the discovery feel more impactful and less like a purely visual phenomenon.\nRefinerAgent > Elias had tended the Solitude Point lighthouse for twenty years, his world confined to the rhythmic sweep of the beam and the ceaseless whisper of the sea. He‚Äôd long ago cataloged every barnacle on the rocks, every gull‚Äôs cry, every shade of grey in the endless fog. Routine was his anchor, solitude his companion. But one blustery evening, while sorting through a dusty crate of salvaged flotsam ‚Äì splintered wood, a child's shoe, a tangle of nets ‚Äì his fingers brushed against something impossibly smooth.\n\nHe pulled out a rolled parchment, unlike any paper he‚Äôd ever seen. It felt cool, almost alive, and pulsed with a faint, emerald light. Unfurling it revealed not ink, but luminous lines tracing an unknown archipelago. Strange symbols, reminiscent of star charts yet unsettlingly alien, dotted the coastlines. They seemed to hum with an ancient energy, a silent song that vibrated in Elias‚Äôs very bones. The map, impossibly, seemed to shift and reconfigure as he watched, its glow intensifying, the luminous lines forming and reforming like currents in a mystical sea.\n\nA profound disbelief warred with a nascent excitement within Elias. Twenty years of predictable tides and predictable stars, and now this. This *thing*. His solitary life had been a quiet harbor, and this map was a tempest, threatening to capsize his carefully constructed peace. Was it a siren‚Äôs call? A cosmic joke? He felt a shiver, a tremor that ran deeper than the rattling of the lighthouse windows. It was the shiver of a man confronting the impossible, the dawning realization that his small, charted world was but a speck against a vaster, stranger ocean.\n\nAs his gaze locked onto a particularly intricate symbol ‚Äì a swirling vortex that seemed to pull at his vision ‚Äì the lighthouse beam above faltered, its steady sweep momentarily dimming as if in response to the map's burgeoning power. A faint, melodic chime, unheard by human ears for millennia, echoed not in the air, but directly in Elias‚Äôs mind, a call from across the shifting, glowing sea. The map wasn't just a discovery; it was an invitation.\nCriticAgent > APPROVED\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n## Section 6: Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)\n\n### üéØ Next Steps\n\nReady for the next challenge? Stay tuned for Day 2 notebooks where we'll learn how to create **Custom Functions, use MCP Tools** and manage **Long-Running operations!**","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Kristopher Overholt](https://www.linkedin.com/in/koverholt) |","metadata":{}}]}